{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import os"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "import os\n",
    "current_file = Path(os.getcwd())\n",
    "root_dir = Path('')\n",
    "sys.path.append(str(root_dir / 'stylegan2-ada-pytorch'))\n",
    "sys.path.append(str(root_dir))\n",
    "sys.path.append(str(root_dir / 'InnerEye-Generative'))\n",
    "# print(sys.path)\n",
    "from azureml.core import Workspace\n",
    "from datetime import datetime\n",
    "from pytorch_lightning import seed_everything, Trainer\n",
    "from pytorch_lightning.callbacks.model_checkpoint import ModelCheckpoint\n",
    "from metrics.get_VGG_model import load_model\n",
    "from loaders.prostate_loader import Prostate2DSimpleDataLoader\n",
    "from models.UNet2D_seg_baseline import Model\n",
    "from helpers.loggers import AzureMLLogger, TensorboardWithImgs, LoggerCollectionWithImgs\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "print('{} -- {}:{}'.format(datetime.now().date(), datetime.now().hour+1, datetime.now().minute), end=' ')\n",
    "print('-- Starting up')\n",
    "seed_everything(1234)\n",
    "# args\n",
    "parser = ArgumentParser()\n",
    "parser.add_argument(\"--batch_size\", default=32, type=int)\n",
    "parser.add_argument(\"--local_dataset_path\", default='', type=str)\n",
    "parser.add_argument(\"--csv_base_name\", default='dataset.csv', type=str)  \n",
    "parser.add_argument(\"--debug\", default=False, type=bool)\n",
    "parser.add_argument(\"--gpu\", default=None, type=int)\n",
    "parser.add_argument(\"--submit_to_azureml\", '-aml', action='store_true', default=False)\n",
    "\n",
    "parser = Trainer.add_argparse_args(parser)\n",
    "parser = Model.add_model_specific_args(parser)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "args = parser.parse_args('')\n",
    "args.gpu = 0\n",
    "#args.resume_from_checkpoint = 'outputs/wassertein_b256_b128_wm/epoch=340-step=57624.ckpt'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "checkpoint_callback = None\n",
    "\n",
    "# run on indicated GPU:\n",
    "if args.gpu is not None and isinstance(args.gpu, int):\n",
    "    # Make sure that it only uses a single GPU..\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = str(args.gpu)\n",
    "    args.gpus = 1\n",
    "\n",
    "# initialise model\n",
    "model = Model(**vars(args))\n",
    "\n",
    "# initialise loader\n",
    "loader_gen = Prostate2DSimpleDataLoader(args.local_dataset_path, args.csv_base_name, args.batch_size, input_channels=1, \n",
    "                                        labels=args.labels,)\n",
    "\n",
    "logger = TensorboardWithImgs('./outputs/UNet')\n",
    "if args.azureml:\n",
    "    AMLlogger = AzureMLLogger()\n",
    "    logger = LoggerCollectionWithImgs([logger, AMLlogger])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import torch\n",
    "mdata = torch.load('outputs/UNet/default/version_12/checkpoints/epoch=67-step=22983.ckpt')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model.load_state_dict(mdata['state_dict'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import monai\n",
    "self = model.to('cuda')\n",
    "\n",
    "ys = []\n",
    "y_preds = []\n",
    "for batch in loader_gen.test_dataloader():\n",
    "    batch = [b.to('cuda') for b in batch]\n",
    "    x, y = self.prepare_batch(batch)\n",
    "    y_hat = self.net(x)\n",
    "    y_pred = torch.argmax(y_hat, 1, keepdim=True)\n",
    "    y_pred = torch.cat([y_pred==i for i in range(y_hat.shape[1])], 1)\n",
    "    ys.append(y)\n",
    "    y_preds.append(y_pred)\n",
    "\n",
    "y = torch.cat(ys)\n",
    "y_pred = torch.cat(y_preds) \n",
    "metrics = monai.metrics.compute_meandice(y_pred, y, include_background=False)\n",
    "non_zero_vols = torch.sum(y[:,1:], (2,3,4)) != 0\n",
    "metrics_means = [metrics[:, i][non_zero_vols[:, i]].mean() for i in range(metrics.shape[1])]\n",
    "metrics_means.append(metrics[non_zero_vols].mean())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "metrics_means"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "path = 'outputs/UNet/AML/'\n",
    "dirs = [path + p + '/outputs/UNet/default/version_0/checkpoints/' for p in os.listdir(path)]\n",
    "ks = []\n",
    "metrics_all = []\n",
    "for _dir in tqdm(dirs):\n",
    "    if os.path.isdir(_dir):\n",
    "            mean_DICE = np.array([float(p.rsplit('mean_DICE_val=')[1].rsplit('.ckpt')[0]) for p in os.listdir(_dir)])\n",
    "            epoch = np.array([int(p.rsplit('epoch=')[1].rsplit('-step')[0]) for p in os.listdir(_dir)])\n",
    "            chpt = _dir + os.listdir(_dir)[np.argmax(epoch[mean_DICE == mean_DICE.max()])]\n",
    "            \n",
    "            mdata = torch.load(chpt)\n",
    "            ks.append(mdata['hyper_parameters']['k_shots'])\n",
    "\n",
    "            model.load_state_dict(mdata['state_dict'])\n",
    "            self = model.to('cuda')\n",
    "            ys = []\n",
    "            y_preds = []\n",
    "            for batch in loader_gen.test_dataloader():\n",
    "                batch = [b.to('cuda') for b in batch]\n",
    "                x, y = self.prepare_batch(batch)\n",
    "                y_hat = self.net(x)\n",
    "                y_pred = torch.argmax(y_hat, 1, keepdim=True)\n",
    "                y_pred = torch.cat([y_pred==i for i in range(y_hat.shape[1])], 1)\n",
    "                ys.append(y)\n",
    "                y_preds.append(y_pred)\n",
    "\n",
    "            y = torch.cat(ys)\n",
    "            y_pred = torch.cat(y_preds) \n",
    "            metrics = monai.metrics.compute_meandice(y_pred, y, include_background=False)\n",
    "            non_zero_vols = torch.sum(y[:,1:], (2,3,4)) != 0\n",
    "            metrics_means = [metrics[:, i][non_zero_vols[:, i]].mean() for i in range(metrics.shape[1])]\n",
    "            metrics_means.append(metrics[non_zero_vols].mean())\n",
    "            metrics_means = torch.stack(metrics_means).detach().cpu()\n",
    "            metrics_all.append(metrics_means)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "chpt = 'outputs/UNet/AML/UNet2D_main_1630502521_8ee37684/outputs/epoch=989-step=84149.ckpt'\n",
    "mdata = torch.load(chpt)\n",
    "ks.append(35)\n",
    "\n",
    "model.load_state_dict(mdata['state_dict'])\n",
    "self = model.to('cuda')\n",
    "ys = []\n",
    "y_preds = []\n",
    "for batch in loader_gen.test_dataloader():\n",
    "    batch = [b.to('cuda') for b in batch]\n",
    "    x, y = self.prepare_batch(batch)\n",
    "    y_hat = self.net(x)\n",
    "    y_pred = torch.argmax(y_hat, 1, keepdim=True)\n",
    "    y_pred = torch.cat([y_pred==i for i in range(y_hat.shape[1])], 1)\n",
    "    ys.append(y)\n",
    "    y_preds.append(y_pred)\n",
    "\n",
    "y = torch.cat(ys)\n",
    "y_pred = torch.cat(y_preds) \n",
    "metrics = monai.metrics.compute_meandice(y_pred, y, include_background=False)\n",
    "non_zero_vols = torch.sum(y[:,1:], (2,3,4)) != 0\n",
    "metrics_means = [metrics[:, i][non_zero_vols[:, i]].mean() for i in range(metrics.shape[1])]\n",
    "metrics_means.append(metrics[non_zero_vols].mean())\n",
    "metrics_means = torch.stack(metrics_means).detach().cpu()\n",
    "metrics_all.append(metrics_means)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "metrics_all = torch.stack(metrics_all).numpy()\n",
    "ks = np.array(ks)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "len(loader_gen.train_dataloader().dataset)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "ax.plot(np.sort(ks), metrics_all[np.argsort(ks), 0], label='femurs')\n",
    "ax.plot(np.sort(ks), metrics_all[np.argsort(ks), 1], label='bladder')\n",
    "ax.plot(np.sort(ks), metrics_all[np.argsort(ks), 2], label='prostate')\n",
    "ax.plot(np.sort(ks), metrics_all[np.argsort(ks), 3], label='all', lw=2)\n",
    "ax.set_xticks(ks)\n",
    "ax.set_xticklabels(list(ks)[:-1] + ['all (10k)'])\n",
    "ax.set_xlabel('Number of training samples')\n",
    "plt.legend()\n",
    "plt.title('Mean DICE score over test set')\n",
    "plt.tight_layout()\n",
    "plt.savefig('mean_DICE_baseline.png')"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.3",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.3 64-bit ('InnerEyePrivate': conda)"
  },
  "interpreter": {
   "hash": "967fa4b60f184cdb1e4943e7e2dc88e1fa22a02ef18c81927ddf08977696de72"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}