{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import torchvision\n",
    "from tqdm.notebook import tqdm\n",
    "from prdc import compute_prdc\n",
    "import numpy as np\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import sys\n",
    "current_file = Path(__file__)\n",
    "root_dir = current_file.parent.parent.parent\n",
    "sys.path.append(str(root_dir / 'InnerEye-Generative'))\n",
    "sys.path.append(str(root_dir))\n",
    "from locations import DATASETPATH\n",
    "DATASETPATH = Path(DATASETPATH)\n",
    "from loaders.prostate_loader import Prostate2DSimpleDataset\n",
    "# Users should import calculate_frechet_distance from:\n",
    "# https://github.com/mseitzer/pytorch-fid/blob/master/src/pytorch_fid/fid_score.py\n",
    "# from metrics.FID import calculate_frechet_distance"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# load pretrained model from torchvision\n",
    "model = torchvision.models.vgg11(pretrained=True, progress=True)\n",
    "model.eval()\n",
    "model = model.to('cuda')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# metrics will collect the metrics for different types of image corruption\n",
    "# these metrics will also be printed directly after their calculation\n",
    "#\n",
    "# For each type of corruption, the metrics are calculated through k_iterations - cross-validation, \n",
    "# where k_iterations is preset to be 5  \n",
    "Metrics = {}\n",
    "k_iterations = 5\n",
    "k_nearest_neigh = 5\n",
    "path = DATASETPATH / '2D' / 'dataset.csv'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "metrics = {'precision':[], 'recall':[],'density':[], 'coverage':[], 'FID':[]}\n",
    "for _ in range(k_iterations):\n",
    "\n",
    "    ds1 = Prostate2DSimpleDataset(path, None, input_channels=3)\n",
    "    ds2 = Prostate2DSimpleDataset(path, None, input_channels=3)\n",
    "    idx = np.arange(len(ds1))\n",
    "    np.random.shuffle(idx)\n",
    "    ds1.df = ds1.df.loc[ds1.df.index[idx[:int(len(ds1)/2)]]]\n",
    "    ds2.df = ds2.df.loc[ds2.df.index[idx[int(len(ds2)/2):]]]\n",
    "\n",
    "    dls = [torch.utils.data.DataLoader(ds,\n",
    "                                    batch_size=16,\n",
    "                                    shuffle=False,\n",
    "                                    drop_last=False,\n",
    "                                    num_workers=8) for ds in [ds1, ds2]]\n",
    "    preds = []\n",
    "    for dl in dls:\n",
    "        _preds = []\n",
    "        for item in dl:\n",
    "            with torch.no_grad():\n",
    "                x = model(item.to('cuda'))\n",
    "            _preds.append(x.cpu())\n",
    "        _preds = torch.cat(_preds, 0)\n",
    "        preds.append(_preds.numpy())\n",
    "    _metrics = compute_prdc(preds[0], preds[1], k_nearest_neigh)\n",
    "\n",
    "    mu = [np.mean(pred, axis=0) for pred in preds]\n",
    "    sigma = [np.cov(pred, rowvar=False) for pred in preds]\n",
    "    FID = calculate_frechet_distance(mu[0], sigma[0], mu[1], sigma[1])\n",
    "    _metrics['FID'] = FID\n",
    "    for key in _metrics:\n",
    "        metrics[key].append(_metrics[key])\n",
    "Metrics['data_vs_data'] = {}\n",
    "for key in metrics:\n",
    "    print(key, np.mean(metrics[key]), np.std(metrics[key]))\n",
    "    Metrics['data_vs_data'][key] = [np.mean(metrics[key]), np.std(metrics[key])]\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def noise(img):\n",
    "    if len(img.shape) == 2:\n",
    "        return np.random.rand(img.shape[0], img.shape[1])\n",
    "    elif len(img.shape) == 3:\n",
    "        return np.random.rand(img.shape[0], img.shape[1], img.shape[2])\n",
    "    else:\n",
    "        raise ValueError\n",
    "Metrics['data_vs_noise'] = {}\n",
    "\n",
    "\n",
    "k_iterations = 5\n",
    "k_nearest_neigh=5\n",
    "path = 'dataset.csv'\n",
    "metrics = {'precision':[], 'recall':[],'density':[], 'coverage':[], 'FID':[]}\n",
    "for _ in range(k_iterations):\n",
    "\n",
    "    ds1 = Prostate2DSimpleDataset(path, None, input_channels=3)\n",
    "    ds2 = Prostate2DSimpleDataset(path, None, input_channels=3, transforms=noise)\n",
    "    idx = np.arange(len(ds1))\n",
    "    np.random.shuffle(idx)\n",
    "    ds1.df = ds1.df.loc[ds1.df.index[idx[:int(len(ds1)/2)]]]\n",
    "    ds2.df = ds2.df.loc[ds2.df.index[idx[int(len(ds2)/2):]]]\n",
    "    dls = [torch.utils.data.DataLoader(ds,\n",
    "                                    batch_size=16,\n",
    "                                    shuffle=False,\n",
    "                                    drop_last=False,\n",
    "                                    num_workers=8) for ds in [ds1, ds2]]\n",
    "    preds = []\n",
    "    for dl in dls:\n",
    "        _preds = []\n",
    "        for item in dl:\n",
    "            with torch.no_grad():\n",
    "                x = model(item.to('cuda'))\n",
    "            _preds.append(x.cpu())\n",
    "        _preds = torch.cat(_preds, 0)\n",
    "        preds.append(_preds.numpy())\n",
    "    _metrics = compute_prdc(preds[0], preds[1], k_nearest_neigh)\n",
    "\n",
    "    mu = [np.mean(pred, axis=0) for pred in preds]\n",
    "    sigma = [np.cov(pred, rowvar=False) for pred in preds]\n",
    "    FID = calculate_frechet_distance(mu[0], sigma[0], mu[1], sigma[1])\n",
    "    _metrics['FID'] = FID\n",
    "    for key in _metrics:\n",
    "        metrics[key].append(_metrics[key])\n",
    "for key in metrics:\n",
    "    print(key, np.mean(metrics[key]), np.std(metrics[key]))\n",
    "    Metrics['data_vs_noise'][key] = [np.mean(metrics[key]), np.std(metrics[key])]\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from scipy.ndimage.filters import gaussian_filter   \n",
    "\n",
    "k_iterations = 5\n",
    "k_nearest_neigh=5\n",
    "path = 'dataset.csv'\n",
    "Gaussian_blur_metrics = {}\n",
    "for Sigma in [.25,.5,.75,1,2]:\n",
    "    metrics = {'precision':[], 'recall':[],'density':[], 'coverage':[], 'FID':[]}\n",
    "\n",
    "    for _ in range(k_iterations):\n",
    "\n",
    "        ds1 = Prostate2DSimpleDataset(path, None, input_channels=3)\n",
    "        ds2 = Prostate2DSimpleDataset(path, None, input_channels=3, transforms=gaussian_filter, transforms_args={'sigma':Sigma})\n",
    "        idx = np.arange(len(ds1))\n",
    "        np.random.shuffle(idx)\n",
    "        ds1.df = ds1.df.loc[ds1.df.index[idx[:int(len(ds1)/2)]]]\n",
    "        ds2.df = ds2.df.loc[ds2.df.index[idx[int(len(ds2)/2):]]]\n",
    "        dls = [torch.utils.data.DataLoader(ds,\n",
    "                                        batch_size=16,\n",
    "                                        shuffle=False,\n",
    "                                        drop_last=False,\n",
    "                                        num_workers=8) for ds in [ds1, ds2]]\n",
    "        preds = []\n",
    "        for dl in dls:\n",
    "            _preds = []\n",
    "            for item in dl:\n",
    "                with torch.no_grad():\n",
    "                    x = model(item.to('cuda'))\n",
    "                _preds.append(x.cpu())\n",
    "            _preds = torch.cat(_preds, 0)\n",
    "            preds.append(_preds.numpy())\n",
    "        _metrics = compute_prdc(preds[0], preds[1], k_nearest_neigh)\n",
    "\n",
    "        mu = [np.mean(pred, axis=0) for pred in preds]\n",
    "        sigma = [np.cov(pred, rowvar=False) for pred in preds]\n",
    "        FID = calculate_frechet_distance(mu[0], sigma[0], mu[1], sigma[1])\n",
    "        _metrics['FID'] = FID\n",
    "        for key in _metrics:\n",
    "            metrics[key].append(_metrics[key])\n",
    "    Gaussian_blur_metrics[Sigma] = {}\n",
    "    for key in metrics:\n",
    "        print(key, np.mean(metrics[key]), np.std(metrics[key]))\n",
    "        Gaussian_blur_metrics[Sigma][key] = [np.mean(metrics[key]), np.std(metrics[key])]\n",
    "Metrics['gaussian_blur'] = Gaussian_blur_metrics"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "tsne = TSNE(perplexity = 5)\n",
    "emb2d = tsne.fit_transform(np.concatenate(preds, 0))\n",
    "n = preds[0].shape[0]\n",
    "plt.scatter(emb2d[:n, 0], emb2d[:n, 1], alpha=.5)\n",
    "plt.scatter(emb2d[n:, 0], emb2d[n:, 1],alpha=.5)\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plt.scatter(emb2d[n:, 0], emb2d[n:, 1],alpha=.5, c='C1')\n",
    "\n",
    "plt.scatter(emb2d[:n, 0], emb2d[:n, 1], alpha=.5, c='C0')\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def multiplicative_noise(img, sigma=1):\n",
    "    return np.clip(img * (1 + np.random.randn(img.shape[0], img.shape[1], img.shape[2]) * sigma), 0, 1)\n",
    "ds2 = Prostate2DSimpleDataset(path, None, input_channels=1, transforms=None, transforms_args={'sigma':.5})\n",
    "plt.imshow(ds2[0].squeeze(), cmap='gray')\n",
    "plt.show()\n",
    "for sigma in [.1,.25,.5,1]:\n",
    "    ds2 = Prostate2DSimpleDataset(path, None, input_channels=1, transforms=multiplicative_noise, transforms_args={'sigma':sigma})\n",
    "    plt.imshow(ds2[0].squeeze(), cmap='gray')\n",
    "    plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "k_iterations = 5\n",
    "k_nearest_neigh=5\n",
    "path = 'dataset.csv'\n",
    "Mult_noise_metrics = {}\n",
    "for Sigma in [.1,.25,.5,.75,1]:\n",
    "    metrics = {'precision':[], 'recall':[],'density':[], 'coverage':[], 'FID':[]}\n",
    "\n",
    "    for _ in range(k_iterations):\n",
    "\n",
    "        ds1 = Prostate2DSimpleDataset(path, None, input_channels=3)\n",
    "        ds2 = Prostate2DSimpleDataset(path, None, input_channels=3, transforms=multiplicative_noise, transforms_args={'sigma':Sigma})\n",
    "        idx = np.arange(len(ds1))\n",
    "        np.random.shuffle(idx)\n",
    "        ds1.df = ds1.df.loc[ds1.df.index[idx[:int(len(ds1)/2)]]]\n",
    "        ds2.df = ds2.df.loc[ds2.df.index[idx[int(len(ds2)/2):]]]\n",
    "\n",
    "        dls = [torch.utils.data.DataLoader(ds,\n",
    "                                        batch_size=16,\n",
    "                                        shuffle=False,\n",
    "                                        drop_last=False,\n",
    "                                        num_workers=8) for ds in [ds1, ds2]]\n",
    "        preds = []\n",
    "        for dl in dls:\n",
    "            _preds = []\n",
    "            for item in dl:\n",
    "                with torch.no_grad():\n",
    "                    x = model(item.to('cuda'))\n",
    "                _preds.append(x.cpu())\n",
    "            _preds = torch.cat(_preds, 0)\n",
    "            preds.append(_preds.numpy())\n",
    "        _metrics = compute_prdc(preds[0], preds[1], k_nearest_neigh)\n",
    "\n",
    "        mu = [np.mean(pred, axis=0) for pred in preds]\n",
    "        sigma = [np.cov(pred, rowvar=False) for pred in preds]\n",
    "        FID = calculate_frechet_distance(mu[0], sigma[0], mu[1], sigma[1])\n",
    "        _metrics['FID'] = FID\n",
    "        for key in _metrics:\n",
    "            metrics[key].append(_metrics[key])\n",
    "    Mult_noise_metrics[Sigma] ={}\n",
    "    for key in metrics:\n",
    "        print(key, np.mean(metrics[key]), np.std(metrics[key]))\n",
    "        Mult_noise_metrics[Sigma][key] = [ np.mean(metrics[key]), np.std(metrics[key])]\n",
    "Metrics['mult_noise'] = Mult_noise_metrics"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from skimage.transform import swirl\n",
    "\n",
    "def swirl_img(img, rotation=0, strength=1, radius=120):\n",
    "    return np.moveaxis(swirl(np.moveaxis(img, 0, -1), rotation=rotation, strength=strength, radius=radius), -1, 0)\n",
    "\n",
    "\n",
    "ds2 = Prostate2DSimpleDataset(path, None, input_channels=1, transforms=None, transforms_args={'sigma':.5})\n",
    "plt.imshow(ds2[0].squeeze(), cmap='gray')\n",
    "plt.show()\n",
    "for sigma in [.1,.25,.5,1]:\n",
    "    ds2 = Prostate2DSimpleDataset(path, None, input_channels=1, transforms=swirl_img, transforms_args={'rotation':0, 'strength': sigma, 'radius':120})\n",
    "    plt.imshow(ds2[0].squeeze(), cmap='gray')\n",
    "    plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "k_iterations = 5\n",
    "k_nearest_neigh=5\n",
    "path = 'dataset.csv'\n",
    "swirl_metrics = {}\n",
    "for Sigma in [.1,.25,.5,.75,1, 2.5, 5,7.5,10]:\n",
    "    metrics = {'precision':[], 'recall':[],'density':[], 'coverage':[], 'FID':[]}\n",
    "\n",
    "    for _ in range(k_iterations):\n",
    "\n",
    "        ds1 = Prostate2DSimpleDataset(path, None, input_channels=3)\n",
    "        ds2 = Prostate2DSimpleDataset(path, None, input_channels=3, transforms=swirl_img, transforms_args={'strength':Sigma})\n",
    "        idx = np.arange(len(ds1))\n",
    "        np.random.shuffle(idx)\n",
    "        ds1.df = ds1.df.loc[ds1.df.index[idx[:int(len(ds1)/2)]]]\n",
    "        ds2.df = ds2.df.loc[ds2.df.index[idx[int(len(ds2)/2):]]]\n",
    "\n",
    "        dls = [torch.utils.data.DataLoader(ds,\n",
    "                                        batch_size=16,\n",
    "                                        shuffle=False,\n",
    "                                        drop_last=False,\n",
    "                                        num_workers=8) for ds in [ds1, ds2]]\n",
    "        preds = []\n",
    "        for dl in dls:\n",
    "            _preds = []\n",
    "            for item in dl:\n",
    "                with torch.no_grad():\n",
    "                    x = model(item.to('cuda'))\n",
    "                _preds.append(x.cpu())\n",
    "            _preds = torch.cat(_preds, 0)\n",
    "            preds.append(_preds.numpy())\n",
    "        _metrics = compute_prdc(preds[0], preds[1], k_nearest_neigh)\n",
    "\n",
    "        mu = [np.mean(pred, axis=0) for pred in preds]\n",
    "        sigma = [np.cov(pred, rowvar=False) for pred in preds]\n",
    "        FID = calculate_frechet_distance(mu[0], sigma[0], mu[1], sigma[1])\n",
    "        _metrics['FID'] = FID\n",
    "        for key in _metrics:\n",
    "            metrics[key].append(_metrics[key])\n",
    "    swirl_metrics[Sigma] ={}\n",
    "    for key in metrics:\n",
    "        print(key, np.mean(metrics[key]), np.std(metrics[key]))\n",
    "        swirl_metrics[Sigma][key] = [ np.mean(metrics[key]), np.std(metrics[key])]\n",
    "Metrics['swirl'] = swirl_metrics"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(list(Metrics))\n",
    "for el in Metrics:\n",
    "    print(list(Metrics[el]))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "Metrics['data_vs_data']['precision']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# PLOT\n",
    "from pylab import figure, show, legend, ylabel\n",
    "def plot_metrics(metrics, base_metrics, Title='', xaxis='', figsize=(10,6), savefig=False):\n",
    "    # create the general figure\n",
    "    fig1 = figure(figsize=figsize)\n",
    "    lines = []\n",
    "    # and the first axes using subplot populated with data \n",
    "    ax1 = fig1.add_subplot(111)\n",
    "    for el in ['precision', 'recall', 'density', 'coverage']:\n",
    "        m =  np.array([base_metrics[el][0]] + [metrics[key][el][0] for key in metrics])\n",
    "        std = np.array([base_metrics[el][1]] + [metrics[key][el][1] for key in metrics])\n",
    "        ax1.fill_between([0] + list(metrics), m-std, m+std, alpha=.5)\n",
    "    \n",
    "    # now, the second axes that shares the x-axis with the ax1\n",
    "    el = 'FID'\n",
    "    m =  np.array([base_metrics[el][0]] + [metrics[key][el][0] for key in metrics])\n",
    "    std = np.array([base_metrics[el][1]] + [metrics[key][el][1] for key in metrics])\n",
    "    ax2 = fig1.add_subplot(111, sharex=ax1, frameon=False)\n",
    "    ax2.fill_between([0] + list(metrics), m-std, m+std, alpha=.5, color='C4')\n",
    "    ax2.yaxis.tick_right()\n",
    "    ax2.yaxis.set_label_position(\"right\")\n",
    "    \n",
    "    for el in ['precision', 'recall', 'density', 'coverage']:\n",
    "        m =  np.array([base_metrics[el][0]] + [metrics[key][el][0] for key in metrics])\n",
    "        std = np.array([base_metrics[el][1]] + [metrics[key][el][1] for key in metrics])\n",
    "        lines = lines + ax1.plot([0] + list(metrics), m)\n",
    "\n",
    "    el = 'FID'\n",
    "    m =  np.array([base_metrics[el][0]] + [metrics[key][el][0] for key in metrics])\n",
    "    std = np.array([base_metrics[el][1]] + [metrics[key][el][1] for key in metrics])\n",
    "    lines = lines + ax2.plot([0] + list(metrics), m, c='C4')\n",
    "\n",
    "    # for the legend, remember that we used two different axes so, we need \n",
    "    # to build the legend manually\n",
    "    legend(tuple(lines),  ['precision', 'recall', 'density', 'coverage', 'FID (RHS)'])\n",
    "    plt.xlabel(xaxis)\n",
    "    plt.title(Title)\n",
    "    if savefig:\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('fig')\n",
    "    show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "list(Metrics)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plot_metrics(Metrics['gaussian_blur'], Metrics['data_vs_data'], \"\"\"Randomly initialised VGG metrics\n",
    "with increasing Gaussian blur\"\"\", 'sigma: data = Gaussian_blur(img, mu=0, sigma=sigma)', figsize=(8,5), savefig=True)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plot_metrics(Metrics['mult_noise'], Metrics['data_vs_data'], \"\"\"Randomly initialised VGG metrics\n",
    "with increasing multiplicative noise\"\"\", 'w: data = img * (1 + w * N(0,1))', figsize=(8,5), savefig=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "_metrics = {}\n",
    "for el in  [0.1, 0.25, 0.5, 0.75, 1, 2.5]:\n",
    "    _metrics[el] = Metrics['swirl'][el]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plot_metrics(_metrics, Metrics['data_vs_data'], \"\"\"Randomly initialised VGG metrics\n",
    "with increasing swirl\"\"\", 's: data = swirl(img, strength=s, radius=120)', figsize=(8,5), savefig=True)\n",
    "\n",
    "plot_metrics(Metrics['swirl'], Metrics['data_vs_data'], \"\"\"Randomly initialised VGG metrics\n",
    "with increasing swirl\"\"\", 's: data = swirl(img, strength=s, radius=120)', figsize=(8,5), savefig=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "Dict = Metrics['gaussian_blur']\n",
    "fix, axs = plt.subplots(1, len(Dict), figsize=(12,10))\n",
    "for ax, sigma in zip(axs, Dict):\n",
    "    ds2 = Prostate2DSimpleDataset(path, None, input_channels=1, transforms=gaussian_filter, transforms_args={'sigma':sigma})\n",
    "    ax.imshow(ds2[0].squeeze(), cmap='gray')\n",
    "    ax.set_title('sigma: {}'.format(sigma))\n",
    "plt.tight_layout()\n",
    "plt.savefig('imgs')\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "Dict = Metrics['mult_noise']\n",
    "fix, axs = plt.subplots(1, len(Dict), figsize=(12,10))\n",
    "for ax, sigma in zip(axs, Dict):\n",
    "    ds2 = Prostate2DSimpleDataset(path, None, input_channels=1, transforms=multiplicative_noise, transforms_args={'sigma':sigma})\n",
    "    ax.imshow(ds2[0].squeeze(), cmap='gray')\n",
    "    ax.set_title('w: {}'.format(sigma))\n",
    "plt.tight_layout()\n",
    "plt.savefig('imgs')    \n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "Dict = Metrics['swirl']\n",
    "fix, axs = plt.subplots(1, len(Dict), figsize=(16,6))\n",
    "for ax, sigma in zip(axs, Dict):\n",
    "    ds2 = Prostate2DSimpleDataset(path, None, input_channels=1, transforms=swirl_img, transforms_args={'strength':sigma})\n",
    "    ax.imshow(ds2[0].squeeze(), cmap='gray')\n",
    "    ax.set_title('s: {}'.format(sigma))\n",
    "plt.tight_layout()\n",
    "plt.savefig('imgs.png')\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.3",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.3 64-bit ('InnerEyePrivate': conda)"
  },
  "interpreter": {
   "hash": "967fa4b60f184cdb1e4943e7e2dc88e1fa22a02ef18c81927ddf08977696de72"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}