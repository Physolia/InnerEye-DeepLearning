{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b80ef2e0-28b9-4a37-823c-ac92e2d10a94",
   "metadata": {},
   "source": [
    "This notebook is to quickly explore the data in the PANDA dataset and familiarise with the processing functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434e814d-e8c1-4850-be0c-8fb29f2a0b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys\n",
    "import math\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from monai.data.image_reader import WSIReader\n",
    "from monai.data import Dataset\n",
    "\n",
    "current_dir = Path(os.getcwd())\n",
    "sys.path.append(str(current_dir.parent))\n",
    "\n",
    "from panda_dataset import PandaDataset, LoadPandaROId\n",
    "from utils.viz_utils import plot_panda_data_sample, load_image_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5993055f-8bab-42fc-ae7b-a77fb30423cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "panda_dir=\"/tmp/datasets/PANDA\"\n",
    "path_train_csv = panda_dir + \"/train.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283775d2-8b2c-46d0-af11-e8b531e4346a",
   "metadata": {},
   "source": [
    "### Train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027434c2-f592-4ef0-b769-09500749c869",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_csv = pd.read_csv(path_train_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a3c145-9ff3-4fd3-8b9b-b05bde895d91",
   "metadata": {},
   "source": [
    "train.csv is the dictionary file used to select which slides to use for training. \n",
    "It does contain some metadata and it doesn't contain any actual image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d6e248-3b4d-4578-84f4-6cb3b4504eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315dcaef-bb10-4f63-8e91-34573e8e57f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_csv.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83fea77a-6d3d-4ad2-ac59-1e25b5b60377",
   "metadata": {},
   "source": [
    "About 10k images in the training set (~90% of the total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3666d5c5-d465-47ff-8476-6edec7e5452b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_csv['isup_grade'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05ecd66-b8d5-44af-941e-f8d6c95b3587",
   "metadata": {},
   "source": [
    "scores are a bit imbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac2b238-096c-40dc-b9ea-f72cbfc1a811",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_csv['data_provider'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db2c1b9-be3c-427f-8a36-ef5f2079f794",
   "metadata": {},
   "source": [
    "data providers are balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6caf9b7f-4ad5-4aa7-8202-f312783bd026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the Monai Dataset, what it adds with respect to the standard dataset?\n",
    "# dataset = Dataset(panda_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84e4cb7-3748-45e0-a7f3-23368fa93171",
   "metadata": {},
   "source": [
    "### Dataset objects and  LoadPandaROId (called inside load_image_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed599a7d-3719-41e1-b592-527e8eceb23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "panda_dataset = PandaDataset(root_dir=panda_dir, n_slides=1)\n",
    "# Using the dataloader to avoid copying the operations in get_item to pass from tiff path to actual tiff\n",
    "loader = DataLoader(panda_dataset, batch_size=1)\n",
    "\n",
    "for _, dict_image in enumerate(loader):\n",
    "    print(dict_image)\n",
    "    print(load_image_dict(dict_image, level=1, margin=64))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27cb73a5-d59a-48b8-bc89-f50c8e006ca1",
   "metadata": {},
   "source": [
    "### Plot single slide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4b8dd9-6ba2-4085-8763-295965f5d582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# staining/normalization seems different in the different channels\n",
    "fig, axes = plt.subplots(ncols=3, nrows=1)\n",
    "for channel in range(3):\n",
    "    axes[channel].imshow(dict_image['image'][channel], clim=(0, 255), cmap='gray')\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4316678b-4f33-44ec-99bf-fde3b9691cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(dict_image['image'].transpose(1,2,0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e842d949-6122-4ada-89c9-95c960288301",
   "metadata": {},
   "source": [
    "### Plot samples at different resolution level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1c81af-527f-4063-8e82-538b69551e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_panda_data_sample(panda_dir, nsamples=12, ncols=4, level=1, margin=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36a059e-b13c-416b-b75b-4ef2ebc3f098",
   "metadata": {},
   "source": [
    "* Each slide looks very different and has different shape! \n",
    "* shape doesn't seem connected with the provider\n",
    "* staining is clearly connected with the provider - images from radboud are lighter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f0fa61-ddca-4b94-b15e-9a1005e9f9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_panda_data_sample(panda_dir, nsamples=12, ncols=4, level=2, margin=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef398f0-d21d-45fe-9b7a-d0cab7825bb8",
   "metadata": {},
   "source": [
    "this will take a bit to run! level 0 is the highest resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edc3695-c481-4a01-b3af-c7a3c8b1076c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_panda_data_sample(panda_dir, nsamples=12, ncols=4, level=0, margin=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ef703c-3cd7-4933-8950-b9a0ef73dfbe",
   "metadata": {},
   "source": [
    "we should focus on a single image to see the difference of the detail depending on the resolution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e05fdf7-03b6-405e-83c6-56c558f8040f",
   "metadata": {},
   "source": [
    "### Pixel distribution (without clipping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2cd070-9e39-4519-888c-e2f29a655398",
   "metadata": {},
   "outputs": [],
   "source": [
    "panda_dataset = PandaDataset(root_dir=panda_dir, nrows=12)\n",
    "loader = DataLoader(panda_dataset, batch_size=1)\n",
    "\n",
    "ncols=3\n",
    "fig, axes = plt.subplots(ncols=ncols, nrows=12, figsize=(7, 18))\n",
    "for i, dict_images in enumerate(loader):\n",
    "    slide_id = dict_images['image_id']\n",
    "    print(f\">>> Slide {slide_id}\")\n",
    "    img = load_image_dict(dict_images, level=1, margin=64)\n",
    "    for ch in range(3):\n",
    "        img = dict_image['image'][0].flatten()\n",
    "        npix = len(img)\n",
    "        axes[i, ch].hist(np.random.choice(dict_image['image'][ch].flatten(), size=int(npix*0.5), replace=False), bins=100);\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f522649-f274-43a6-8860-82de5cabec0f",
   "metadata": {},
   "source": [
    "distributions don't seem wildly different, good. This is a small sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00bbbc1-51b7-4393-bd93-35a51e4ecf75",
   "metadata": {},
   "source": [
    "### Pixel distribution (with clipping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7b155d-e322-4682-abe7-5992e0dc4896",
   "metadata": {},
   "outputs": [],
   "source": [
    "panda_dataset = PandaDataset(root_dir=panda_dir, nrows=12)\n",
    "loader = DataLoader(panda_dataset, batch_size=1)\n",
    "\n",
    "ncols=3\n",
    "fig, axes = plt.subplots(ncols=ncols, nrows=12, figsize=(7, 18))\n",
    "for i, dict_images in enumerate(loader):\n",
    "    slide_id = dict_images['image_id']\n",
    "    print(f\">>> Slide {slide_id}\")\n",
    "    img = load_image_dict(dict_images, level=1, margin=64)\n",
    "    for ch in range(3):\n",
    "        img = dict_image['image'][0].flatten()\n",
    "        npix = len(img)\n",
    "        axes[i, ch].hist(np.random.choice(dict_image['image'][ch].flatten(), size=int(npix*0.5), replace=False), bins=100);\n",
    "        axes[i, ch].set_ylim([0,50000])\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dda68c4-ebd3-4c18-8642-277fda8e9611",
   "metadata": {},
   "source": [
    "Note: the background is not always exactly 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:histo]",
   "language": "python",
   "name": "conda-env-histo-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
