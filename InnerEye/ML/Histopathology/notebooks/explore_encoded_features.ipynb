{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b80ef2e0-28b9-4a37-823c-ac92e2d10a94",
   "metadata": {},
   "source": [
    "This notebook is to explore the features and attentions from different encoders (ImageNet, ImageNetSimCLR, InnerEyeSSL, HistoSSL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434e814d-e8c1-4850-be0c-8fb29f2a0b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy\n",
    "import torch\n",
    "\n",
    "from sklearn.metrics import silhouette_samples, davies_bouldin_score, calinski_harabasz_score\n",
    "\n",
    "# the working directory is not correctly picked up in sys.path\n",
    "current_dir = Path(os.getcwd())\n",
    "radiomics_root = current_dir.parent.parent.parent\n",
    "if (radiomics_root / \"InnerEyePrivate\").is_dir():\n",
    "    radiomics_root_str = str(radiomics_root)\n",
    "    if radiomics_root_str not in sys.path:\n",
    "        print(f\"Adding to sys.path: {radiomics_root_str}\")\n",
    "        sys.path.insert(0, radiomics_root_str)\n",
    "        sys.path.insert(0, str(radiomics_root / \"innereye-deeplearning\"))\n",
    "        print(f\"Sys path {sys.path}\")\n",
    "from InnerEye.ML.Histopathology.utils.analysis_plot_utils import plot_box_whisker, get_tsne_projection, get_umap_projection, plot_projected_features_2d, plot_histogram, normalize_array_minmax, normalize_array_mean\n",
    "from InnerEye.ML.Histopathology.utils.download_utils import download_file_if_necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cead442",
   "metadata": {},
   "source": [
    "### Download test outputs (CSV and encoded features) from AML runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5993055f-8bab-42fc-ae7b-a77fb30423cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = Path(\"outputs/\")\n",
    "run_ids = [\"hsharma_features_viz:hsharma_features_viz_1636727694_8881c83d\",\n",
    "            \"hsharma_features_viz:hsharma_features_viz_1636727732_ef0ab3fc\",\n",
    "            \"hsharma_features_viz:hsharma_features_viz_1636727760_899692b2\",\n",
    "            \"hsharma_features_viz:hsharma_features_viz_1636727790_73839184\"]\n",
    "features_filename = 'test_encoded_features.pickle'\n",
    "csv_filename = 'test_output.csv'\n",
    "encoder_names = [\"ImageNet\", \"ImageNetSimCLR\", \"InnerEyeSSL\",\"HistoSSL\"]\n",
    "\n",
    "for run_id, encoder_name in zip(run_ids, encoder_names):\n",
    "    print(f\"Downloading files for run {run_id} and {encoder_name} encoder.\")\n",
    "    download_file_if_necessary(run_id=run_id, remote_dir=output_dir, download_dir=output_dir, filename=features_filename)\n",
    "    download_file_if_necessary(run_id=run_id, remote_dir=output_dir, download_dir=output_dir, filename=csv_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098a8be2",
   "metadata": {},
   "source": [
    "### Visualize t-SNE projection of encoded features at slide-level"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c870526",
   "metadata": {},
   "source": [
    "Slide-level feature obtained as mean of all tile-level features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7704555b",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes=['MSS','MSI']\n",
    "\n",
    "for run_id, encoder_name in zip(run_ids, encoder_names):\n",
    "    file_features = output_dir / run_id.split(\":\")[1] / \"outputs\" / features_filename\n",
    "    file_outputs = output_dir / run_id.split(\":\")[1] / \"outputs\" / csv_filename\n",
    "    print(f\"Loading test encoded features for {encoder_name} encoder...\")\n",
    "    lists_features = torch.load(file_features)  \n",
    "\n",
    "    print(f\"Loading test output CSV for {encoder_name} encoder...\")\n",
    "    metadata = pd.read_csv(file_outputs)\n",
    "    labels = metadata.groupby('slide_id')['true_label'].agg(numpy.mean)\n",
    "\n",
    "    print(f\"Collecting test slide-level features for {encoder_name} encoder...\")\n",
    "    slides = []\n",
    "    for slide_features in lists_features:\n",
    "        tiles = []\n",
    "        for tile_features in slide_features:\n",
    "            tiles.append(tile_features)  \n",
    "        mean_slide_feature = torch.mean(torch.stack(tiles), dim=0)\n",
    "        slides.append(mean_slide_feature)\n",
    "\n",
    "    slides_list = torch.stack(slides).numpy()  \n",
    "    print(len(slides_list[1]))\n",
    "    print(f\"Running slide-level t-sne for {encoder_name} encoder...\")\n",
    "    tsne_slides = get_tsne_projection(features=slides_list, n_components=2, init='random', random_state=0, verbose=True, n_jobs=-1)\n",
    "    plot_projected_features_2d(data=tsne_slides, labels=labels, classes=classes, title=encoder_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283775d2-8b2c-46d0-af11-e8b531e4346a",
   "metadata": {},
   "source": [
    "### Visualize t-SNE projection of encoded features at tile-level \n",
    "\n",
    "This will take few hours to run for each encoder as # tiles > 66K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027434c2-f592-4ef0-b769-09500749c869",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes=['MSS','MSI']\n",
    "\n",
    "for run_id, encoder_name in zip(run_ids, encoder_names):\n",
    "    file_features = output_dir / run_id.split(\":\")[1] / \"outputs\" / features_filename\n",
    "    file_outputs = output_dir / run_id.split(\":\")[1] / \"outputs\" / csv_filename\n",
    "    print(f\"Loading test encoded features for {encoder_name} encoder...\")\n",
    "    lists_features = torch.load(file_features)  \n",
    "\n",
    "    print(f\"Loading test output CSV for {encoder_name} encoder...\")\n",
    "    metadata = pd.read_csv(file_outputs)\n",
    "    labels = metadata['true_label']\n",
    "\n",
    "    print(f\"Collecting test tile-level features for {encoder_name} encoder...\")\n",
    "    tiles = []\n",
    "    for slide_features in lists_features:\n",
    "        for tile_features in slide_features:\n",
    "            tiles.append(tile_features)\n",
    "\n",
    "    tiles_list = torch.stack(tiles).numpy()  \n",
    "    print(f\"Running tile-level t-sne for {encoder_name} encoder...\")\n",
    "    tsne_tiles = get_tsne_projection(features=tiles_list, n_components=2, init='random', random_state=0, verbose=True, n_jobs=-1)\n",
    "    plot_projected_features_2d(data=tsne_tiles, labels=labels, classes=classes, title=encoder_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2f7e2f",
   "metadata": {},
   "source": [
    "### Visualize UMAP projection of encoded features at slide-level"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c0c44a",
   "metadata": {},
   "source": [
    "Slide-level feature obtained as mean of all tile-level features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c92f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes=['MSS','MSI']\n",
    "\n",
    "for run_id, encoder_name in zip(run_ids, encoder_names):\n",
    "    file_features = output_dir / run_id.split(\":\")[1] / \"outputs\" / features_filename\n",
    "    file_outputs = output_dir / run_id.split(\":\")[1] / \"outputs\" / csv_filename\n",
    "    print(f\"Loading test encoded features for {encoder_name} encoder...\")\n",
    "    lists_features = torch.load(file_features)  \n",
    "\n",
    "    print(f\"Loading test output CSV for {encoder_name} encoder...\")\n",
    "    metadata = pd.read_csv(file_outputs)\n",
    "    labels = metadata.groupby('slide_id')['true_label'].agg(numpy.mean)\n",
    "\n",
    "    print(f\"Collecting test slide-level features for {encoder_name} encoder...\")\n",
    "    slides = []\n",
    "    for slide_features in lists_features:\n",
    "        tiles = []\n",
    "        for tile_features in slide_features:\n",
    "            tiles.append(tile_features)  \n",
    "        mean_slide_feature = torch.mean(torch.stack(tiles), dim=0)\n",
    "        slides.append(mean_slide_feature)\n",
    "\n",
    "    slides_list = torch.stack(slides).numpy()  \n",
    "    print(f\"Running slide-level umap for {encoder_name} encoder...\")\n",
    "    tsne_slides = get_umap_projection(features=slides_list, n_components=2, init='random', random_state=0, verbose=True, n_jobs=-1)\n",
    "    plot_projected_features_2d(data=tsne_slides, labels=labels, classes=classes, title=encoder_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7adde06",
   "metadata": {},
   "source": [
    "### Visualize UMAP projection of encoded features at tile-level "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1fa63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes=['MSS','MSI']\n",
    "\n",
    "for run_id, encoder_name in zip(run_ids, encoder_names):\n",
    "    file_features = output_dir / run_id.split(\":\")[1] / \"outputs\" / features_filename\n",
    "    file_outputs = output_dir / run_id.split(\":\")[1] / \"outputs\" / csv_filename\n",
    "    print(f\"Loading test encoded features for {encoder_name} encoder...\")\n",
    "    lists_features = torch.load(file_features)  \n",
    "\n",
    "    print(f\"Loading test output CSV for {encoder_name} encoder...\")\n",
    "    metadata = pd.read_csv(file_outputs)\n",
    "    labels = metadata['true_label']\n",
    "\n",
    "    print(f\"Collecting test tile-level features for {encoder_name} encoder...\")\n",
    "    tiles = []\n",
    "    for slide_features in lists_features:\n",
    "        for tile_features in slide_features:\n",
    "            tiles.append(tile_features)\n",
    "\n",
    "    tiles_list = torch.stack(tiles).numpy()  \n",
    "    print(f\"Running tile-level umap for {encoder_name} encoder...\")\n",
    "    tsne_tiles = get_umap_projection(features=tiles_list, n_components=2, init='random', random_state=0, verbose=True, n_jobs=-1)\n",
    "    plot_projected_features_2d(data=tsne_tiles, labels=labels, classes=classes, title=encoder_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36ef868",
   "metadata": {},
   "source": [
    "### Attention histograms - unnormalized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602f90a8",
   "metadata": {},
   "source": [
    "Histogram of attentions without any normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a262bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for run_id, encoder_name in zip(run_ids, encoder_names):\n",
    "    file_outputs = output_dir / run_id.split(\":\")[1] / \"outputs\" / csv_filename\n",
    "    print(f\"Loading test output CSV for {encoder_name} encoder...\")\n",
    "    metadata = pd.read_csv(file_outputs)\n",
    "    bag_attention = metadata['bag_attn']\n",
    "\n",
    "    print(\"Plotting unnormalized attention histograms...\")\n",
    "    plot_histogram(data=bag_attention, title=encoder_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45550aad",
   "metadata": {},
   "source": [
    "### Attention histograms - normalized (zero mean and unit variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795b1110",
   "metadata": {},
   "source": [
    "Histogram of attentions after normalizing to zero mean and unit variance (x_i-mean(x)/std(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1245ddc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for run_id, encoder_name in zip(run_ids, encoder_names):\n",
    "    file_outputs = output_dir / run_id.split(\":\")[1] / \"outputs\" / csv_filename\n",
    "    print(f\"Loading test output CSV for {encoder_name} encoder...\")\n",
    "    metadata = pd.read_csv(file_outputs)\n",
    "\n",
    "    slide_ids = metadata.groupby('slide_id').groups.keys()\n",
    "    bag_attention_normalized_mean = []\n",
    "    for slide_id in slide_ids:\n",
    "        slide_attn = metadata.loc[metadata['slide_id'] == slide_id, 'bag_attn']\n",
    "        normalized_attn_mean = normalize_array_mean(slide_attn)\n",
    "        bag_attention_normalized_mean.extend(normalized_attn_mean)\n",
    "    \n",
    "    print(\"Plotting normalized attention histograms...\")\n",
    "    plot_histogram(data=bag_attention_normalized_mean, title=encoder_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974b8b1b",
   "metadata": {},
   "source": [
    "### Attention histograms - normalized (range 0-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a0d7d2",
   "metadata": {},
   "source": [
    "Histogram of attentions after normalizing to range 0-1 (x_i-min(x))/(max(x)-min(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39955d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for run_id, encoder_name in zip(run_ids, encoder_names):\n",
    "    file_outputs = output_dir / run_id.split(\":\")[1] / \"outputs\" / csv_filename\n",
    "    print(f\"Loading test output CSV for {encoder_name} encoder...\")\n",
    "    metadata = pd.read_csv(file_outputs)\n",
    "\n",
    "    slide_ids = metadata.groupby('slide_id').groups.keys()\n",
    "    bag_attention_normalized_minmax = []\n",
    "    for slide_id in slide_ids:\n",
    "        slide_attn = metadata.loc[metadata['slide_id'] == slide_id, 'bag_attn']\n",
    "        normalized_attn_minmax = normalize_array_minmax(slide_attn)\n",
    "        bag_attention_normalized_minmax.extend(normalized_attn_minmax)\n",
    "    \n",
    "    print(\"Plotting normalized attention histograms...\")\n",
    "    plot_histogram(data=bag_attention_normalized_minmax, title=encoder_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253673fa",
   "metadata": {},
   "source": [
    "### Box-whisker plot to compare attentions of different encoders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4153a476",
   "metadata": {},
   "source": [
    "Compare attention distributions of different encoders in box-whisker plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c59ce4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_attention_list = []\n",
    "for run_id, encoder_name in zip(run_ids, encoder_names):\n",
    "    metadata = pd.read_csv(output_dir / run_id.split(\":\")[1] / \"outputs\" / csv_filename)\n",
    "    bag_attention = metadata['bag_attn']\n",
    "    bag_attention_list.append(bag_attention.tolist())\n",
    "\n",
    "plot_box_whisker(data_list=bag_attention_list, column_names=encoder_names, show_outliers=False, title=\"Boxplot of attentions\")\n",
    "plot_box_whisker(data_list=bag_attention_list, column_names=encoder_names, show_outliers=True, title=\"Boxplot of attentions with outliers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6316d0",
   "metadata": {},
   "source": [
    "### How well are the encoded features separated between slides?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fcc539",
   "metadata": {},
   "source": [
    "Scores to find distances between clusters (a slide is a cluster). A good encoder should not lead to good separation with respect to slides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fadce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for run_id, encoder_name in zip(run_ids, encoder_names):\n",
    "    file_features = output_dir / run_id.split(\":\")[1] / \"outputs\" / features_filename\n",
    "    file_outputs = output_dir / run_id.split(\":\")[1] / \"outputs\" / csv_filename\n",
    "    print(f\"Loading test encoded features for {encoder_name} encoder...\")\n",
    "    lists_features = torch.load(file_features)  \n",
    "\n",
    "    print(f\"Loading test output CSV for {encoder_name} encoder...\")\n",
    "    metadata = pd.read_csv(file_outputs)\n",
    "\n",
    "    print(f\"Collecting test tile-level features for {encoder_name} encoder...\")    \n",
    "    tiles = []\n",
    "    for slide_features in lists_features:\n",
    "        for tile_features in slide_features:\n",
    "            tiles.append(tile_features)\n",
    "\n",
    "    tiles_list = torch.stack(tiles).numpy() \n",
    "    labels = metadata['slide_id']\n",
    "\n",
    "    print(\"Finding clustering scores (a slide is a cluster)...\")\n",
    "    slide_ids = metadata.groupby('slide_id').groups.keys()\n",
    "    silhouette_coeffs = silhouette_samples(tiles_list, labels, n_jobs=-1)\n",
    "    slide_coeffs = []\n",
    "    for slide_id in slide_ids:\n",
    "        slide_silhouette_coeffs = silhouette_coeffs[metadata['slide_id'] == slide_id]\n",
    "        slide_coeffs.append(numpy.mean(slide_silhouette_coeffs))\n",
    "\n",
    "    print(f\"Silhouette clustering quality index for {encoder_name} encoder: \", numpy.mean(slide_coeffs))\n",
    "    print(f\"Davis-Bouldin index for {encoder_name} encoder: \", davies_bouldin_score(tiles_list, labels))\n",
    "    print(f\"Calinski-Harabasz index  for {encoder_name} encoder: \", calinski_harabasz_score(tiles_list, labels))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fed29a51b9091993eaaef6c9485d6a9ef7bedfd5201255f59ee7e61b233b2074"
  },
  "kernelspec": {
   "display_name": "Python [conda env:histo]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
